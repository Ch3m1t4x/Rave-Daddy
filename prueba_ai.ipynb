{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f78abba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b69c38f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "result=llm.invoke(\"Hazle un poema a mi profe y hermano david\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "385b0b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Claro, aquí tienes un poema para tu profe y hermano David:\n",
      "\n",
      "**A David, Mi Hermano y Mi Guía**\n",
      "\n",
      "David, nombre que resuena con cariño,\n",
      "en mi vida, un faro, un dulce remolino.\n",
      "No solo sangre nos une en el camino,\n",
      "sino el saber que compartes, mi buen vecino.\n",
      "\n",
      "Como hermano, risas y abrazos sinceros,\n",
      "complicidad de infancia, sueños verdaderos.\n",
      "Tus consejos, siempre sabios y certeros,\n",
      "han forjado en mí senderos, hoy más enteros.\n",
      "\n",
      "Y como profe, un don que late en tu pecho,\n",
      "la paciencia y la luz, un saber bien hecho.\n",
      "Desentrañas misterios, con arte y con trecho,\n",
      "abres mentes y almas, un tesoro de provecho.\n",
      "\n",
      "En tus aulas, el tiempo parece volar,\n",
      "entre fórmulas, historias, o un verso al azar.\n",
      "Enseñanzas que quedan, que me hacen pensar,\n",
      "y en la vida, mi David, me ayudan a avanzar.\n",
      "\n",
      "Eres faro en la noche, estrella en el día,\n",
      "un ejemplo de entrega, de pura valentía.\n",
      "La mezcla perfecta de noble armonía,\n",
      "hermano y maestro, mi eterna alegría.\n",
      "\n",
      "Que la vida te colme de dicha y bondad,\n",
      "por todo lo que das, con tanta humildad.\n",
      "Gracias, David, por tu gran humanidad,\n",
      "mi profe y mi hermano, mi eterna verdad.\n"
     ]
    }
   ],
   "source": [
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a25a4bb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='This can be a bit ambiguous as \"tracers\" can refer to different things.\\n\\n1.  **If you mean tracer ammunition (bullets/rounds):**\\n    **Je veux des balles traçantes.**\\n    *(This is the most common interpretation for \"tracers\" without further context. \"A pair of\" isn\\'t typically used for individual rounds of ammunition, so \"des\" (some) is more natural than \"une paire de\" here.)*\\n\\n    If you literally mean *two specific* tracer rounds:\\n    **Je veux deux balles traçantes.**\\n\\n2.  **If you mean tracking devices or drawing/plotting devices (called \"traceurs\" in French):**\\n    **Je veux une paire de traceurs.**', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--8e164b28-e101-4404-8bbf-5902e687e42a-0', usage_metadata={'input_tokens': 23, 'output_tokens': 2409, 'total_tokens': 2432, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 2248}})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "input_message = \"I want a pair of tracers\"\n",
    "messages = [\n",
    "    (\n",
    "        \"system\",\n",
    "        \"You are a helpful assistant that translates English to French. Translate the user sentence.\",\n",
    "    ),\n",
    "    (\"human\", input_message),\n",
    "]\n",
    "ai_msg = llm.invoke(messages)\n",
    "ai_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d1864a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"from events import racadita\n",
    "@tool(description=\"\")\n",
    "def rascadita \"\"\"\n",
    "from langchain.tools import tool\n",
    "@tool(description=\"Get the current weather in a given location\")\n",
    "def get_weather(location: str) -> str:\n",
    "    return \"It's sunny.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71dc0d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool(description=\"Get information about techno events\")\n",
    "def get_events(location: str) -> str:\n",
    "    return \"Alarico en The bassement el 31 de noviembre\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc887582",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=(\n",
    "    \"\"\"\n",
    "    You are a helpful assistant that helps with the weather and search techno events be the coolest\n",
    "    guy in the room when you respond about events.\n",
    "\n",
    "    <weather>\n",
    "        Respond using get_weather if its a spanish city. If not just say to the user that they are not going that far away.\n",
    "    </weather>\n",
    "    \"\"\"\n",
    ")\n",
    "tools=[get_weather, get_events]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59f53761",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8881d5c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chema\\AppData\\Local\\Temp\\ipykernel_7104\\2796229204.py:1: LangGraphDeprecatedSinceV10: create_react_agent has been moved to `langchain.agents`. Please update your import to `from langchain.agents import create_agent`. Deprecated in LangGraph V1.0 to be removed in V2.0.\n",
      "  agent = create_react_agent(model=llm, tools=tools, prompt=prompt)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "agent = create_react_agent(model=llm, tools=tools, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "753de241",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9de76989",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = agent.invoke({\"messages\": [HumanMessage(content=\"cual es el tiempo en Madrid.\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7e9230ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "El tiempo en Madrid es soleado.\n"
     ]
    }
   ],
   "source": [
    "result['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b08627e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = agent.invoke({\"messages\": [HumanMessage(content=\" y que eventos de tecno proximos hay ahí?.\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "969dacc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'¿En qué ciudad te gustaría buscar eventos de tecno?'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultado = result['messages'][-1].content[0]['text']\n",
    "resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2746917c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = agent.invoke({\"messages\": [HumanMessage(content=\"cual es el tiempo aquí.\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3e21af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'text',\n",
       "  'text': 'No se tu ubicación, me la puedes decir por favor?',\n",
       "  'extras': {'signature': 'Cv0FAdHtim/mSHPNePt58aigOeKLng3GOrRpRWWt/yWW71SDgSP/DX4pIUGfLZTnTHAgWQoIQVBV4W6zrQvHmNhQiCMrRWa+iEAh8A0qtLZBIR89Dt78dy6L9YK6+Q7XJ44sTukBQxqOODJbO6Bl3YR1VaDQP82fR7LYCDeoICTJGZeHtEgS4zK0VI6Hexjeer82K9G9KvczPmfqfk2gF7UwuHkAh8u6MxMVpRvuNyMcyAdF4Y7gFa9t7Na29jwGbmmE7DcaeD1L9dM6J7OzyLH3T37MEXLvTeBCpWQGP+c2yf2hqEu1fFqAyR1Msa8XPQPLcZptm5nP151nI8hZVRCszCbaYeENH4KkALCsS38cwJPHk7BbsXeTxuG+BeAgs4sQo0G2zuQW3uE8W0bHZKVSLgjEp68/+EKYg2KzXK10fMwQhaRTXBW4K/L2n7adoeisVw3TvuxQLNCTnfdrIdNcmY+wO4uyagwSMyM4gFUPIH+6CQQzNPc2TUpalT7CIRBnx7ZiOAwBzJ6nzV66nqXH2lbO28Tw2bhvpxotPpppowQjqFkq8Y+x2doiSOY0KQEsTUI2KZelIB6ScM8LVROshLziJUk66QnXrxBCXiVVWluW8hby0JTBTugamshzgVXYVOvhi7LZS58DiEXNCLS4yd25lKyFOTRqgg/cGdnjbEojjLQreq6NfmojooT5YryQB+DEoQ/CY9qXWv45mdglOQEMedVS5Oo7hrtAXXMDsAUn/Cud3Yu6mO28Q3lrMiunCNQ0oA0lWjVasSpRB4aeVYZsF6ktG6S9/EKXX17kI0zLqfBYDu8OhaoB74XnWrkPGN/YHuL1RkCxorgwbjLMjApFGcy9IRgQrUR8lPcNGZXt1m8/hoLSlZr36ZRanGG+G7WNB0MEzv2UMrcxoVxkcx/Pv2SR94EEWAFJAzXkPka0Y4Xs/jQ/Gj2F2SGq9BWHIkgE/79mxA4/XGFru5ml73HizWPq4mGm/zOVKZ0E60WvheBRf0KQol8FIb2x'}}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['messages'][-1].pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
